{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c52e56cb-2ca7-4fb7-ba43-2aea1856f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.signal import resample\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f04a2975-e97e-4c2f-8d57-7cae953c4fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Device & dtype setup\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "print(torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02f7cecb-2dc6-4aae-8bfe-090da49926dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Whisper Large V3 Turbo\n",
    "model_id = r\"D:\\ASR_Model\\whisper-large-v3-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dcf6c4e-2090-4194-928c-2cd1e6bd81ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51866, 1280, padding_idx=50257)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch_dtype,\n",
    "    #low_cpu_mem_usage=True,\n",
    "    use_safetensors=True,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cfc318b-3345-476d-af4e-be4a2b6becb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4df83343-1438-46a0-99fd-e9929dd10be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "114f03d3-8104-4021-93bf-29e06badee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start speaking. Press Ctrl+C to stop.\n",
      "\n",
      "Meine kurze Vorstellung. Hallo.\n",
      "Meine kurze Vorstellung. Hallo. Ich heiße Maria. Ich bin 26 Jahre alt und komme aus\n",
      "Meine kurze Vorstellung. Hallo. Ich heiße Maria. Ich bin 26 Jahre alt und komme aus Seit sechs Monaten lebe ich in Deutschland, in München.\n",
      "Meine kurze Vorstellung. Hallo. Ich heiße Maria. Ich bin 26 Jahre alt und komme aus Seit sechs Monaten lebe ich in Deutschland, in München. Ich arbeite als Lehrerin und unterrichte Englisch.\n",
      "Meine kurze Vorstellung. Hallo. Ich heiße Maria. Ich bin 26 Jahre alt und komme aus Seit sechs Monaten lebe ich in Deutschland, in München. Ich arbeite als Lehrerin und unterrichte Englisch. In meiner Freizeit gehe ich gerne spazieren und treffe mich mit Freundschaften.\n",
      "Meine kurze Vorstellung. Hallo. Ich heiße Maria. Ich bin 26 Jahre alt und komme aus Seit sechs Monaten lebe ich in Deutschland, in München. Ich arbeite als Lehrerin und unterrichte Englisch. In meiner Freizeit gehe ich gerne spazieren und treffe mich mit Freundschaften. Ich liebe es, neue Kulturen zu entdecken und zu reisen.\n",
      "Meine kurze Vorstellung. Hallo. Ich heiße Maria. Ich bin 26 Jahre alt und komme aus Seit sechs Monaten lebe ich in Deutschland, in München. Ich arbeite als Lehrerin und unterrichte Englisch. In meiner Freizeit gehe ich gerne spazieren und treffe mich mit Freundschaften. Ich liebe es, neue Kulturen zu entdecken und zu reisen. Ich spreche Spanisch, Englisch und lerne Deutsch.\n",
      "Meine kurze Vorstellung. Hallo. Ich heiße Maria. Ich bin 26 Jahre alt und komme aus Seit sechs Monaten lebe ich in Deutschland, in München. Ich arbeite als Lehrerin und unterrichte Englisch. In meiner Freizeit gehe ich gerne spazieren und treffe mich mit Freundschaften. Ich liebe es, neue Kulturen zu entdecken und zu reisen. Ich spreche Spanisch, Englisch und lerne Deutsch. Mein Ziel ist es, bald fließend Deutsch zu sprechen und zu lernen.\n",
      "\n",
      "Transcription stopped.\n",
      "\n",
      "Final Transcript:\n",
      " Meine kurze Vorstellung. Hallo. Ich heiße Maria. Ich bin 26 Jahre alt und komme aus Seit sechs Monaten lebe ich in Deutschland, in München. Ich arbeite als Lehrerin und unterrichte Englisch. In meiner Freizeit gehe ich gerne spazieren und treffe mich mit Freundschaften. Ich liebe es, neue Kulturen zu entdecken und zu reisen. Ich spreche Spanisch, Englisch und lerne Deutsch. Mein Ziel ist es, bald fließend Deutsch zu sprechen und zu lernen.\n"
     ]
    }
   ],
   "source": [
    "# Real-time streaming function\n",
    "def real_time_transcribe(duration_chunk=4.0, input_rate=44100, model_rate=16000):\n",
    "    buffer = []\n",
    "    print(\"Start speaking. Press Ctrl+C to stop.\\n\")\n",
    "\n",
    "    def callback(indata, frames, time, status):\n",
    "        if status:\n",
    "            print(\"Status:\", status)\n",
    "        audio = indata[:, 0]  # mono channel\n",
    "        resampled = resample(audio, int(len(audio) * model_rate / input_rate)).astype(np.float32)\n",
    "        #result = pipe(resampled, generate_kwargs={\"language\": \"de\"})\n",
    "        result = pipe(resampled, generate_kwargs={\"language\": \"german\", \"task\": \"transcribe\"})\n",
    "        text = result.get(\"text\", \"\").strip()\n",
    "        if text:\n",
    "            buffer.append(text)\n",
    "            print(\" \".join(buffer))\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(callback=callback,\n",
    "                            channels=1,\n",
    "                            samplerate=input_rate,\n",
    "                            blocksize=int(duration_chunk * input_rate),\n",
    "                            dtype='float32'):\n",
    "            while True:\n",
    "                sd.sleep(1000)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTranscription stopped.\")\n",
    "        print(\"\\nFinal Transcript:\\n\", \" \".join(buffer))\n",
    "\n",
    "# Start real-time transcription\n",
    "real_time_transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d553e-069f-4ae3-97da-62a35f404be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51200fb8-d6f4-4b1f-8a8c-b64a1b8d46ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_gpu_new",
   "language": "python",
   "name": "cuda_gpu_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
