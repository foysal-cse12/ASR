{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f71638c-fbd7-44a6-a2fb-a9c51bf10b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flashtext\n",
    "#!pip install rapidfuzz\n",
    "#!pip install sounddevice \n",
    "#!pip install torch \n",
    "#!pip install transformers\n",
    "#!pip install scipy \n",
    "#!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52e56cb-2ca7-4fb7-ba43-2aea1856f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.signal import resample\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c17dc07-1766-4823-b8fd-089ceb3a0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashtext import KeywordProcessor\n",
    "from rapidfuzz import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04a2975-e97e-4c2f-8d57-7cae953c4fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Device & dtype setup\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "print(torch_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f778ae6-8f98-402b-a430-7723397258d8",
   "metadata": {},
   "source": [
    "### Load Whisper Large V3 Turbo\n",
    "#### model from hugging face: \n",
    "##### (1)https://huggingface.co/openai/whisper-large-v3-turbo \n",
    "##### (2)https://huggingface.co/primeline/whisper-large-v3-turbo-german "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f7cecb-2dc6-4aae-8bfe-090da49926dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = \"primeline/whisper-large-v3-turbo-german\"\n",
    "#model_id = \"openai/whisper-large-v3-turbo\"\n",
    "#If you load the model from local Machine\n",
    "#model_id = r\"D:\\ASR_Model\\whisper-large-v3-turbo\"\n",
    "model_id = r\"D:\\ASR_Model\\whisper-large-v3-turbo-german\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dcf6c4e-2090-4194-928c-2cd1e6bd81ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51866, 1280, padding_idx=50257)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch_dtype,\n",
    "    #low_cpu_mem_usage=True,\n",
    "    use_safetensors=True,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfc318b-3345-476d-af4e-be4a2b6becb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df83343-1438-46a0-99fd-e9929dd10be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a72e118-aeb5-4582-8a46-4631bf9fe1e4",
   "metadata": {},
   "source": [
    "### Initialize flashtext KeywordProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f1c310-23b7-47d9-b849-0d84e9e3b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keyword_processor = KeywordProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c013d95-dd49-4212-8726-c23a18312a0a",
   "metadata": {},
   "source": [
    "### Custom vocabulary corrections / Add custom vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd28e58-1c18-48e8-862c-7343ad1dcee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custom_vocab = {\n",
    "    \"*Blutdruck*\": [\"blut druck\", \"bluttruck\", \"blut druk\", \"blud druck\"],\n",
    "    \"*Herzinfark*t\": [\"herz infarkt\", \"herz in fakt\", \"herzin fackt\", \"hertz infarkt\"],\n",
    "    \"*Diabetes*\": [\"di abetes\", \"diabetis\", \"diabedes\", \"di abetis\"],\n",
    "    \"*Asthma*\": [\"asma\", \"ast ma\", \"asth mar\", \"azma\"],\n",
    "    \"*Krebs*\": [\"crebs\", \"crabs\", \"kreps\", \"kreppz\"],\n",
    "    \"*Fieber*\": [\"fiba\", \"fiba\", \"fever\", \"fiebar\"],\n",
    "    \"*Infektion*\": [\"infec tion\", \"in fektion\", \"infekshun\", \"infactshion\"],\n",
    "    \"*Antibiotika*\": [\"antibiotika\", \"anti biotika\", \"antybiotika\", \"anti biotika\"],\n",
    "    \"*Schmerzmittel*\": [\"schmertz mittel\", \"shmertzmittel\", \"smertz mittel\", \"schmerz mitl\"],\n",
    "    \"*Notaufnahme*\": [\"not aufnahme\", \"noto fnahme\", \"notaufnahm\", \"note aufnahme\"],\n",
    "    \"*Herzrhythmusstörung*\": [\"herz rhythmus störung\", \"hertz rithmus störung\", \"herz rytmus störung\"],\n",
    "    \"*Lungenentzündung*\": [\"lungen entzuendung\", \"lungen entzündung\", \"lungen enzündung\", \"lungen entzundung\"],\n",
    "    \"*Arzneimittel*\": [\"arz neimittel\", \"arznei mittel\", \"arznaimittel\", \"ars nai mittel\"],\n",
    "    \"*Jet Engine*\": [\"jet injun\", \"judging\", \"jett in june\",\"jet in june\"],\n",
    "    \"*Quantum Bit*\": [\"quantum bet\", \"kwantum bit\"],\n",
    "    \"*ChatGenie*\": [\"chat genie\", \"chat jeanie\", \"chat gini\", \"chatt ginny\"],\n",
    "    \"*Foysal*\": [\"abdullah\", \"abdulla\", \"abdula\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a6334-b86f-4b72-a262-e701d6b162d3",
   "metadata": {},
   "source": [
    "### Populate FlashText and a map for fuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "135f9883-d8e3-4885-ab42-38a24542aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dialect_map = {}\n",
    "for correct_term, variants in custom_vocab.items():\n",
    "    for variant in variants:\n",
    "        keyword_processor.add_keyword(variant.lower(), correct_term)\n",
    "        dialect_map[variant.lower()] = correct_term\n",
    "\n",
    "variant_list = list(dialect_map.keys())\n",
    "\n",
    "# Fuzzy fallback function\n",
    "def fuzzy_correction(text, threshold=90):\n",
    "    words = text.split()\n",
    "    corrected = []\n",
    "    for word in words:\n",
    "        if word in variant_list:\n",
    "            corrected.append(dialect_map[word])\n",
    "        else:\n",
    "            match = process.extractOne(word, variant_list)\n",
    "            if match and match[1] >= threshold:\n",
    "                corrected.append(dialect_map[match[0]])\n",
    "            else:\n",
    "                corrected.append(word)\n",
    "    return \" \".join(corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37c644-af94-4468-8955-148fb37905dc",
   "metadata": {},
   "source": [
    "### Real-time streaming function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e1b49b5-5161-4b7b-8de0-67c3b80d4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def real_time_transcribe(duration_chunk=3.0, input_rate=44100, model_rate=16000):\n",
    "    buffer = []\n",
    "    print(\"Start speaking...\\n\")\n",
    "\n",
    "    def callback(indata, frames, time, status):\n",
    "        if status:\n",
    "            print(\"Status:\", status)\n",
    "        audio = indata[:, 0]  # mono\n",
    "        resampled = resample(audio, int(len(audio) * model_rate / input_rate)).astype(np.float32)\n",
    "        result = pipe(resampled, generate_kwargs={\"language\": \"german\", \"task\": \"transcribe\"})\n",
    "        text = result.get(\"text\", \"\").strip()\n",
    "\n",
    "        if text:\n",
    "            flashtext_corrected = keyword_processor.replace_keywords(text.lower())\n",
    "            final_corrected = fuzzy_correction(flashtext_corrected)\n",
    "            buffer.append(final_corrected)\n",
    "            print(\" \".join(buffer), end=\"\\r\")\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(callback=callback,\n",
    "                            channels=1,\n",
    "                            samplerate=input_rate,\n",
    "                            blocksize=int(duration_chunk * input_rate),\n",
    "                            dtype='float32'):\n",
    "            while True:\n",
    "                sd.sleep(1000)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTranscription stopped.\")\n",
    "        print(\"\\nFinal Transcript:\\n\", \" \".join(buffer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68fdbd60-cb97-4ffd-917c-1baaeb6ab161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start speaking...\n",
      "\n",
      "beim telefonieren mein telefon klingelt. ich nehme den anruf an. *Diabetes* ist meine meine freundin maria. sie fragt, wie *Diabetes* mir geht. wir sprechen über unsere pläne für das wochenende. maria schlägt vor, ins kino zu gehen. wir nehmen zu *Lungenentzündung* wir vereinbaren eine zeit. verabschieden uns *Lungenentzündung* legen auch beim telefonieren\n",
      "Transcription stopped.\n",
      "\n",
      "Final Transcript:\n",
      " beim telefonieren mein telefon klingelt. ich nehme den anruf an. *Diabetes* ist meine meine freundin maria. sie fragt, wie *Diabetes* mir geht. wir sprechen über unsere pläne für das wochenende. maria schlägt vor, ins kino zu gehen. wir nehmen zu *Lungenentzündung* wir vereinbaren eine zeit. verabschieden uns *Lungenentzündung* legen auch beim telefonieren\n"
     ]
    }
   ],
   "source": [
    "#Start real-time transcription\n",
    "real_time_transcribe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de7cf9a-0c1d-4fd3-a114-30222c897462",
   "metadata": {},
   "source": [
    "### References\n",
    "##### https://pypi.org/project/flashtext/\n",
    "##### https://pypi.org/project/RapidFuzz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d553e-069f-4ae3-97da-62a35f404be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51200fb8-d6f4-4b1f-8a8c-b64a1b8d46ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee7e0e-e534-4e2a-9e0d-51828b6a44b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_gpu_new",
   "language": "python",
   "name": "cuda_gpu_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
